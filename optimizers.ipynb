{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMia6RHIbyPunPYz5rqbvV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maman08/dailyCode/blob/main/optimizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FQpw1YyPeE6t"
      },
      "outputs": [],
      "source": [
        "!mkdir -p Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p checkpoints\n"
      ],
      "metadata": {
        "id": "OgkRAvjJeHMa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O Data/winequality-red.csv https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxlQseEteV-F",
        "outputId": "0d01f577-361b-4fa8-eaf0-4398e0388333"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-17 09:01:02--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘Data/winequality-red.csv’\n",
            "\n",
            "Data/winequality-re     [ <=>                ]  82.23K   465KB/s    in 0.2s    \n",
            "\n",
            "2025-05-17 09:01:03 (465 KB/s) - ‘Data/winequality-red.csv’ saved [84199]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import VERBOSE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, BatchNormalization, Dropout\n",
        "from keras.callbacks import EarlyStopping , ModelCheckpoint\n",
        "from keras.optimizers import  SGD , Adam , RMSprop , Nadam , Adamax\n",
        "SEED =2017\n",
        "np.random.seed(SEED)\n",
        "data = pd.read_csv('/content/Data/winequality-red.csv' ,sep=';')\n",
        "y= data['quality']\n",
        "x= data.drop(['quality'],axis=1)\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=SEED)\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2,random_state=SEED)\n",
        "def create_model(optimizer_name):\n",
        "  model = Sequential([\n",
        "    Input(shape=(x_train.shape[1],)),\n",
        "    Dense(100, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "  return model\n",
        "optimizers_Aval = {\n",
        "    'sgd': SGD(learning_rate=0.001),\n",
        "    'adam' : Adam(),\n",
        "    'adamx' : Adamax(),\n",
        "    'rmsprop' : RMSprop(),\n",
        "    'nadam' : Nadam()\n",
        "}\n",
        "results= []\n",
        "for opt in optimizers_Aval:\n",
        "  print(f\"Training with optimizer : {opt}\")\n",
        "  model = create_model(opt)\n",
        "  model.compile(loss='mse' , optimizer=optimizers_Aval[opt],metrics=['mae'])\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "  hist = model.fit(x_train.values , y_train , epochs=5 ,callbacks=[early_stopping] ,validation_data= (x_val.values,y_val))\n",
        "  # Get the best epoch and validation loss\n",
        "  best_epoch = np.argmin(hist.history['val_loss'])\n",
        "  best_val_loss = np.min(hist.history['val_loss'])\n",
        "\n",
        "  # Evaluate on test set\n",
        "  test_loss, test_acc = model.evaluate(x_test.values, y_test, verbose=0)\n",
        "\n",
        "  # Append results\n",
        "  results.append({\n",
        "      'optimizer': opt,\n",
        "      'best_epoch': best_epoch,\n",
        "      'best_val_loss': best_val_loss,\n",
        "      'test_loss': test_loss,\n",
        "      'test_accuracy': test_acc\n",
        "  })\n",
        "\n",
        "# Convert to DataFrame for easier viewing\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.sort_values(by='test_loss'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCfolQ0WebJv",
        "outputId": "8b8e2f79-5622-4f11-9dd6-942049b05f6d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with optimizer : sgd\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 23.1212 - mae: 4.5521 - val_loss: 14.5424 - val_mae: 3.2519\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.0627 - mae: 2.0949 - val_loss: 9.2689 - val_mae: 2.6139\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6395 - mae: 1.5932 - val_loss: 5.2325 - val_mae: 1.9352\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6019 - mae: 1.2869 - val_loss: 3.5678 - val_mae: 1.5883\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0859 - mae: 1.1674 - val_loss: 2.3592 - val_mae: 1.2593\n",
            "Training with optimizer : adam\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 15.2556 - mae: 3.5422 - val_loss: 26.4438 - val_mae: 4.2149\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 4.0819 - mae: 1.6315 - val_loss: 7.2731 - val_mae: 2.3220\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1203 - mae: 1.1597 - val_loss: 3.0837 - val_mae: 1.4421\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8466 - mae: 1.0525 - val_loss: 1.2985 - val_mae: 0.9134\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6586 - mae: 1.0222 - val_loss: 0.8141 - val_mae: 0.6998\n",
            "Training with optimizer : adamx\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 41.8526 - mae: 6.2921 - val_loss: 26.1933 - val_mae: 4.7863\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 20.8778 - mae: 4.3928 - val_loss: 15.4847 - val_mae: 3.4888\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8015 - mae: 2.7931 - val_loss: 11.1140 - val_mae: 2.8111\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5787 - mae: 1.9680 - val_loss: 7.4343 - val_mae: 2.1643\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4205 - mae: 1.7348 - val_loss: 4.6728 - val_mae: 1.6528\n",
            "Training with optimizer : rmsprop\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 15.8647 - mae: 3.6134 - val_loss: 30.6912 - val_mae: 4.3753\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2088 - mae: 1.6738 - val_loss: 8.6056 - val_mae: 2.4471\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1877 - mae: 1.1247 - val_loss: 1.8392 - val_mae: 1.0932\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4039 - mae: 0.9360 - val_loss: 0.8839 - val_mae: 0.7659\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3429 - mae: 0.9013 - val_loss: 0.7252 - val_mae: 0.6891\n",
            "Training with optimizer : nadam\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - loss: 22.4145 - mae: 4.5014 - val_loss: 22.7172 - val_mae: 3.8327\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2261 - mae: 2.1071 - val_loss: 8.2876 - val_mae: 2.3400\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4191 - mae: 1.2214 - val_loss: 1.8503 - val_mae: 1.0444\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5636 - mae: 0.9869 - val_loss: 1.0216 - val_mae: 0.8013\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4069 - mae: 0.9195 - val_loss: 0.7665 - val_mae: 0.7071\n",
            "  optimizer  best_epoch  best_val_loss  test_loss  test_accuracy\n",
            "3   rmsprop           4       0.725192   0.595985       0.615757\n",
            "4     nadam           4       0.766481   0.633089       0.629540\n",
            "1      adam           4       0.814099   0.718487       0.660185\n",
            "0       sgd           4       2.359189   2.495495       1.317538\n",
            "2     adamx           4       4.672840   4.654860       1.669004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HWmXT1DEiWtp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}